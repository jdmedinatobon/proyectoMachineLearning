{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CrearArchivoDescriptores.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdmedinatobon/proyectoMachineLearning/blob/master/CrearArchivoDescriptores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFrqP4m8CNBB",
        "colab_type": "code",
        "outputId": "bf9210fa-7c9e-4496-bda5-e3a50a4786c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#En esta celda se incluyen los comandos necesarios para instalar las librerias requeridas.\n",
        "#Esta solo se debe ejecutar cada vez que se inicia el Runtime.\n",
        "!pip install mahotas"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mahotas in /usr/local/lib/python3.6/dist-packages (1.4.8)\n",
            "Requirement already satisfied: numpy in /tensorflow-2.0.0/python3.6 (from mahotas) (1.17.3)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement unzip (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for unzip\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlJnlfnH8hzQ",
        "colab_type": "code",
        "outputId": "dea792be-0fc1-4636-c343-ae6282634df2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Aqui se importan las librerias necesarias para correr el codigo.\n",
        "#Antes de correr esta celda se deben ejecutar la anterior para instalar las librerias.\n",
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import csv\n",
        "import mahotas as mh\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import scipy.stats as st"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx0o5JjLNgue",
        "colab_type": "code",
        "outputId": "95f27337-cf07-4d96-e329-599923c38864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Se descomprime el archivo con los datos preprocesados\n",
        "!unzip Datos.zip #En verdad no es este archivo.\n",
        "\n",
        "#Indica si existe alguna GPU.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Datos.zip\n",
            "   creating: Datos/\n",
            "   creating: Datos/ds001497-download/\n",
            "   creating: Datos/ds001497-download/.datalad/\n",
            "  inflating: Datos/ds001497-download/.datalad/.gitattributes  \n",
            " extracting: Datos/ds001497-download/.datalad/config  \n",
            "  inflating: Datos/ds001497-download/.gitattributes  \n",
            "   creating: Datos/ds001497-download/code/\n",
            "   creating: Datos/ds001497-download/code/build-bids-crc/\n",
            "  inflating: Datos/ds001497-download/code/build-bids-crc/bids_anat.sh  \n",
            "  inflating: Datos/ds001497-download/code/build-bids-crc/bids_anat_deface.sh  \n",
            "  inflating: Datos/ds001497-download/code/build-bids-crc/bids_anat_rename.sh  \n",
            "  inflating: Datos/ds001497-download/code/build-bids-crc/bids_func.sh  \n",
            "  inflating: Datos/ds001497-download/code/build-bids-crc/bids_func_rename.sh  \n",
            "  inflating: Datos/ds001497-download/code/build-bids-crc/bids_func_sidecar.py  \n",
            "  inflating: Datos/ds001497-download/code/build-bids-crc/bids_phasemap.sh  \n",
            "  inflating: Datos/ds001497-download/code/build-bids-crc/bids_phasemap_rename.sh  \n",
            "  inflating: Datos/ds001497-download/code/build-bids-crc/bids_task_events.py  \n",
            "  inflating: Datos/ds001497-download/code/build-bids-crc/README.txt  \n",
            "   creating: Datos/ds001497-download/code/pydeface/\n",
            " extracting: Datos/ds001497-download/code/pydeface-2.0.zip  \n",
            "  inflating: Datos/ds001497-download/code/pydeface/.gitignore  \n",
            "  inflating: Datos/ds001497-download/code/pydeface/LICENSE  \n",
            " extracting: Datos/ds001497-download/code/pydeface/MANIFEST.in  \n",
            "   creating: Datos/ds001497-download/code/pydeface/pydeface/\n",
            "   creating: Datos/ds001497-download/code/pydeface/pydeface/data/\n",
            "  inflating: Datos/ds001497-download/code/pydeface/pydeface/data/facemask.nii.gz  \n",
            " extracting: Datos/ds001497-download/code/pydeface/pydeface/data/mean_reg2mean.nii.gz  \n",
            "  inflating: Datos/ds001497-download/code/pydeface/pydeface/utils.py  \n",
            " extracting: Datos/ds001497-download/code/pydeface/pydeface/__init__.py  \n",
            "  inflating: Datos/ds001497-download/code/pydeface/pydeface/__main__.py  \n",
            "  inflating: Datos/ds001497-download/code/pydeface/README.txt  \n",
            "  inflating: Datos/ds001497-download/code/pydeface/setup.py  \n",
            "   creating: Datos/ds001497-download/sub-01/\n",
            "   creating: Datos/ds001497-download/sub-01/anat/\n",
            "  inflating: Datos/ds001497-download/sub-01/anat/sub-01_T1w.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-01/anat/sub-01_T1w_defaced.nii  \n",
            "   creating: Datos/ds001497-download/sub-01/func/\n",
            "  inflating: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-1_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-1_bold.nii  \n",
            " extracting: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-1_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-1_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-1_events.tsv  \n",
            "  inflating: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-2_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-2_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-2_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-2_events.tsv  \n",
            "  inflating: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-3_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-3_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-3_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-3_events.tsv  \n",
            "  inflating: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-4_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-4_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-4_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-4_events.tsv  \n",
            "  inflating: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-5_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-5_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-5_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-5_events.tsv  \n",
            "  inflating: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-6_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-6_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-6_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-01/func/sub-01_task-LTM_run-6_events.tsv  \n",
            "   creating: Datos/ds001497-download/sub-02/\n",
            "   creating: Datos/ds001497-download/sub-02/anat/\n",
            "  inflating: Datos/ds001497-download/sub-02/anat/sub-02_T1w.nii.gz  \n",
            "   creating: Datos/ds001497-download/sub-02/func/\n",
            "  inflating: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-1_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-1_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-1_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-1_events.tsv  \n",
            "  inflating: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-2_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-2_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-2_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-2_events.tsv  \n",
            "  inflating: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-3_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-3_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-3_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-3_events.tsv  \n",
            "  inflating: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-4_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-4_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-4_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-4_events.tsv  \n",
            "  inflating: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-5_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-5_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-5_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-5_events.tsv  \n",
            "  inflating: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-6_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-6_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-6_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-02/func/sub-02_task-LTM_run-6_events.tsv  \n",
            "   creating: Datos/ds001497-download/sub-03/\n",
            "   creating: Datos/ds001497-download/sub-03/anat/\n",
            "  inflating: Datos/ds001497-download/sub-03/anat/sub-03_T1w.nii.gz  \n",
            "   creating: Datos/ds001497-download/sub-03/func/\n",
            "  inflating: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-1_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-1_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-1_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-1_events.tsv  \n",
            "  inflating: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-2_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-2_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-2_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-2_events.tsv  \n",
            "  inflating: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-3_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-3_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-3_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-3_events.tsv  \n",
            "  inflating: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-4_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-4_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-4_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-4_events.tsv  \n",
            "  inflating: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-5_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-5_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-5_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-5_events.tsv  \n",
            "  inflating: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-6_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-6_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-6_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-03/func/sub-03_task-LTM_run-6_events.tsv  \n",
            "   creating: Datos/ds001497-download/sub-04/\n",
            "   creating: Datos/ds001497-download/sub-04/anat/\n",
            "  inflating: Datos/ds001497-download/sub-04/anat/sub-04_T1w.nii.gz  \n",
            "   creating: Datos/ds001497-download/sub-04/func/\n",
            "  inflating: Datos/ds001497-download/sub-04/func/sub-04_task-LTM_run-1_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-04/func/sub-04_task-LTM_run-1_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-04/func/sub-04_task-LTM_run-1_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-04/func/sub-04_task-LTM_run-1_events.tsv  \n",
            "  inflating: Datos/ds001497-download/sub-04/func/sub-04_task-LTM_run-2_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-04/func/sub-04_task-LTM_run-2_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-04/func/sub-04_task-LTM_run-2_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-04/func/sub-04_task-LTM_run-2_events.tsv  \n",
            "  inflating: Datos/ds001497-download/sub-04/func/sub-04_task-LTM_run-3_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-04/func/sub-04_task-LTM_run-3_bold.nii.gz  \n",
            "  inflating: Datos/ds001497-download/sub-04/func/sub-04_task-LTM_run-3_events.json  \n",
            "  inflating: Datos/ds001497-download/sub-04/func/sub-04_task-LTM_run-3_events.tsv  \n",
            "  inflating: Datos/ds001497-download/sub-04/func/sub-04_task-LTM_run-4_bold.json  \n",
            " extracting: Datos/ds001497-download/sub-04/func/sub-04_task-LTM_run-4_bold.nii.gz  \n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3EfMD2h-Jjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Es la ruta del archivo raiz de los datos preprocesados.\n",
        "pathArchivoDatosPreprocesados = \"PruebaDatos\"\n",
        "\n",
        "#Estas 2 variables se utilizan para recorrer cada carpeta de los datos.\n",
        "sub = [0, 0]\n",
        "run = 1\n",
        "\n",
        "#Funcion que retorna el nombre del archivo que contiene las imagenes de resonancia magnetica.\n",
        "#pSub: Indica la persona a la cual se le tomaron las imagenes.\n",
        "#pRun: Indica el run para una persona. Cada run incluye 180 muestras de imagenes.\n",
        "def darNombreArchivoImagenes(pSub, pRun):\n",
        "  return \"PruebaDatos/ds001497-download/sub-\"+str(pSub[0])+str(pSub[1])+\"/func/sub-\" + str(pSub[0]) + str(pSub[1]) + \"_task-LTM_run-\" + str(pRun) + \"_bold.nii.gz\"\n",
        "\n",
        "#Funcion que retorna el nombre del archivo que contiene las etiquetas correspondientes a las imagenes de resonancia magnetica.\n",
        "#pSub: Indica la persona a la cual se le tomaron las imagenes.\n",
        "#pRun: Indica el run para una persona. Cada run incluye 180 muestras de imagenes.\n",
        "def darNombreArchivoEtiquetas(pSub, pRun):\n",
        "  return \"PruebaDatos/ds001497-download/sub-\"+str(pSub[0])+str(pSub[1])+\"/func/sub-\" + str(pSub[0]) + str(pSub[1]) + \"_task-LTM_run-\" + str(pRun) + \"_events.tsv\"\n",
        "\n",
        "#Funcion que obtiene el conjunto de 30 imagenes de 64x64 utilizados para el proyecto.\n",
        "def obtenerImagenes(pImagenes):\n",
        "  \n",
        "  imagenes = np.zeros((64,64,30,30))\n",
        "\n",
        "  for indice in range(0,15):\n",
        "    imagenes[:,:,:,2*indice] = pImagenes[:,:,:,1+indice*13]\n",
        "    imagenes[:,:,:,2*indice+1] = pImagenes[:,:,:,2+indice*13]\n",
        "\n",
        "  return imagenes\n",
        "\n",
        "#Funcion que obtiene las etiquetas y las convierte a su correspondiente numero entero de acuerdo con la siguiente regla:\n",
        "#object -> 0\n",
        "#place -> 1\n",
        "#face -> 2\n",
        "def leerEtiquetas(pArchivoEtiquetas):\n",
        "  etiquetas = []\n",
        "\n",
        "  with open(pArchivoEtiquetas) as tsvfile:\n",
        "    reader = csv.DictReader(tsvfile, dialect='excel-tab')\n",
        "    for row in reader:\n",
        "      \n",
        "      etiqueta = row['trial_type']\n",
        "\n",
        "      if(etiqueta == 'object'):\n",
        "\n",
        "        etiquetas.append(0)\n",
        "        etiquetas.append(0)\n",
        "      elif(etiqueta == 'place'):\n",
        "\n",
        "        etiquetas.append(1)\n",
        "        etiquetas.append(1)\n",
        "      elif(etiqueta == 'face'):\n",
        "\n",
        "        etiquetas.append(2)\n",
        "        etiquetas.append(2)\n",
        "      else:\n",
        "        print(\"Error en el formato. Existe una clase distinta a object, place o face\")\n",
        "\n",
        "  return etiquetas\n",
        "\n",
        "#Funcion que genera una matriz de NumPy con los datos leidos de los archivos.\n",
        "def importarDatos():\n",
        "  datosPreprocesados = np.zeros((64,64,30,1800))\n",
        "  etiquetasPreprocesados = np.zeros(1800)\n",
        "\n",
        "  contador = 0\n",
        "  for s1 in range(1,2):#(1,11)\n",
        "\n",
        "    if(s1 == 10):\n",
        "      sub[0] = 1\n",
        "      sub[1] = 0\n",
        "    else:\n",
        "      sub[1] = s1\n",
        "\n",
        "      for r in range(1,2):#(1,7)\n",
        "        run = r\n",
        "        archivoImagenes = darNombreArchivoImagenes(sub, run)\n",
        "        archivoEtiquetas = darNombreArchivoEtiquetas(sub, run)\n",
        "\n",
        "        imagenes = nib.load(archivoImagenes).get_fdata()\n",
        "        etiquetas = leerEtiquetas(archivoEtiquetas)\n",
        "\n",
        "        muestras = obtenerImagenes(imagenes)\n",
        "\n",
        "        for indice in range(0,30):\n",
        "            datosPreprocesados[:,:,:,30*contador+indice] = muestras[:,:,:,indice]\n",
        "            etiquetasPreprocesados[30*contador+indice] = etiquetas[indice]\n",
        "\n",
        "        contador+=1\n",
        "\n",
        "    return datosPreprocesados, etiquetasPreprocesados.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4-duenQTB7E",
        "colab_type": "code",
        "outputId": "98e5fdc6-b114-4a8d-89bb-a0021b0794cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#En esta linea de codigo se importan los datos y se almacenan en las variables datosPreprocesados (correspondiente a las imagenes) y en etiquetasPreprocesadas (las etiquetas).\n",
        "print(\"Importando datos...\")\n",
        "datosPreprocesados, etiquetasPreprocesados = importarDatos()\n",
        "print(\"Se importaron correctamente.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Importando datos...\n",
            "Se importaron correctamente.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4oSi4itJOCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calcularDescriptoresPrimerOrden(pImagenes):\n",
        "\n",
        "  mean = np.mean(pImagenes, axis = None)\n",
        "  var = np.var(pImagenes, axis = None)\n",
        "  kur = st.kurtosis(pImagenes, axis = None)\n",
        "  ske = st.skew(pImagenes, axis = None)\n",
        "\n",
        "  descriptores = np.append([mean, var],[kur, ske])\n",
        "\n",
        "  return descriptores\n",
        "\n",
        "#Calcula los descriptores a partir de un grupo de imagenes de fMRI.\n",
        "def calcularDescriptores(pImagenes):\n",
        "  #Faltan los descriptores del histograma\n",
        "  descPrimer = calcularDescriptoresPrimerOrden(pImagenes)\n",
        "  descSegundo = mh.features.haralick(pImagenes, ignore_zeros=True, preserve_haralick_bug=False, compute_14th_feature=False, return_mean=True, return_mean_ptp=False, use_x_minus_y_variance=False, distance=1)\n",
        "\n",
        "  descriptores = np.append(descPrimer,descSegundo)\n",
        "\n",
        "  return descriptores\n",
        "\n",
        "#Funcion que retorna el texto de la descripcion del archivo de descriptores.\n",
        "def darTextoIntroduccion(pEscala):\n",
        "  texto = \"Este archivo incluye los descriptores calculados a partir de los datos preprocesados. \\nLos datos brutos fueron obtenidos del \\\n",
        "dataset de imágenes de resonancia magnética funcional que se puede encontrar en https://openneuro.org/datasets/ds001497/versions/1.0.1.\\n\\\n",
        "A estos datos se les realizó un preprocesamiento utilizando fmriprep (ESTO TOCA VER SI SI SIRVE AL FIN) y finalmente se calcularon los \\\n",
        "descriptores con una escala de grises de \" + str(pEscala) + \".\\nEstos descriptores son (EL NUMERO QUE SEA) e incluyen:\\nEnergía, etc.... (AGREGAR LOS QUE FALTAN Y ORDENARLOS CORRECTAMENTE).\\n\\\n",
        "Finalmente, cada muestra incluye a la clase a la cual pertenece. Existen 3 clases y se indican con un número de 0 a 2 que corresponden a:\\n\\\n",
        "objeto -> 0\\n\\\n",
        "lugar -> 1\\n\\\n",
        "rostro -> 2\\n\\\n",
        "media;varianza;kurtosis;skewness;....;clase AGREGAR TODAS LAS VARIABLES ACA EN ORDEN SIGUIENDO LA CONVENCIÓN DE SEPARARLOS CON ;\"\n",
        "\n",
        "  return texto\n",
        "\n",
        "#Funcion que retorna un string con los descriptores y clases separados por ;.\n",
        "#Esta cadena sera utilizada para generar el archivo de texto con los descriptores calculados y su etiqueta.\n",
        "def darLinea(pDescriptores, pEtiqueta):\n",
        "  separador = \";\"\n",
        "  muestra = []\n",
        "  return separador.join(pDescriptores.astype(str)) + separador + str(pEtiqueta)\n",
        "\n",
        "#Funcion que genera el archivo de texto con los datos de los descriptores y su correspondiente etiqueta.\n",
        "#Este archivo recibe el nombre de datosDescriptores.txt e incluye los descriptores y sus etiquetas separadas por ;\n",
        "#y una descripcion del archivo.\n",
        "def crearArchivoDescriptores():\n",
        "  escala = 256\n",
        "\n",
        "  print(\"Generando archivo de descriptores...\")\n",
        "  archivo = open(\"datosDescriptores.txt\", \"w+\")\n",
        "\n",
        "  intro = darTextoIntroduccion(escala)\n",
        "  archivo.write(intro)\n",
        "  archivo.write(\"\\n\")\n",
        "\n",
        "  start = time.time()\n",
        "\n",
        "  #Esto deberia iterar hasta 1800, pero por ahora menos.\n",
        "  for i in range(0,30):\n",
        "    imagenes = datosPreprocesados[:,:,:,i]\n",
        "    imagenes = escala*(imagenes/imagenes.max())\n",
        "    imagenes = imagenes.astype(int)\n",
        "\n",
        "    descriptores = calcularDescriptores(imagenes)\n",
        "    linea = darLinea(descriptores, etiquetasPreprocesados[i])\n",
        "    archivo.write(linea)\n",
        "    archivo.write(\"\\n\")\n",
        "    \n",
        "  print(\"Archivo generado exitosamente.\")\n",
        "  print(\"Tiempo: {} segundos\".format(time.time()-start))\n",
        "\n",
        "  archivo.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPzTB7hiFE7G",
        "colab_type": "code",
        "outputId": "a81e477b-0514-41b8-a8b2-4a427fa4084f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "crearArchivoDescriptores()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generando archivo de descriptores...\n",
            "Archivo generado exitosamente.\n",
            "Tiempo: 4.744805574417114 segundos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjzFtd2a1tp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}